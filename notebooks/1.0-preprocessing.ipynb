{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing CGE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following code lines are necessary to import custom module\n",
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import boto3\n",
    "import io\n",
    "import json\n",
    "import pandas as pd\n",
    "from src.preprocessing.data_preparation_and_cleaning import change_features_names, get_station_name\n",
    "from src.preprocessing.feature_engineer import get_wind_components, resample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS credentials to read files on S3 bucket\n",
    "f = open('../credentials.json')\n",
    "credentials = json.load(f)\n",
    "\n",
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id=credentials[\"Access key ID\"],\n",
    "    aws_secret_access_key=credentials[\"Secret access key\"]\n",
    "    )\n",
    "\n",
    "s3_resource = boto3.resource(\n",
    "    's3',\n",
    "    aws_access_key_id=credentials[\"Access key ID\"],\n",
    "    aws_secret_access_key=credentials[\"Secret access key\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = []\n",
    "for year in list(range(2009, 2019+1)):  \n",
    "    prefix=f\"raw/{year}/\"\n",
    "    prefix_objs = s3_resource.Bucket(\"cge\").objects.filter(Prefix=prefix)\n",
    "    keys = [obj.key for obj in prefix_objs]\n",
    "    for key in keys:\n",
    "        obj = s3_client.get_object(Bucket=\"cge\", Key=key)\n",
    "        df = pd.read_csv(io.BytesIO(obj[\"Body\"].read()))\n",
    "        df_full.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cge = pd.concat(df_full, ignore_index=True)\n",
    "cge = cge.drop_duplicates(ignore_index=True)\n",
    "cge = get_station_name(cge)\n",
    "cge[['Posto Nome']] = cge[['Posto Nome']].replace('NaN', '1000300')\n",
    "\n",
    "cge = cge[[\n",
    "    'Posto',\n",
    "    'Posto Nome',\n",
    "    'DATA',\n",
    "    'PLU(mm)',\n",
    "    'Vel.VT(m/s)',\n",
    "    'Dir.VT(o)',\n",
    "    'Temp(oC)',\n",
    "    'Umid.Rel.(%)',\n",
    "    'Pressão(mb)',\n",
    "    'Rajada.VT(m/s)',\n",
    "    'Sens. Térmica(°C)'\n",
    "    ]]\n",
    "\n",
    "cge = cge[cge['Posto Nome'].isin(['Sé', 'Lapa', 'Pirituba', 'Penha', 'Jabaquara', 'Parelheiros'])]\n",
    "cge = change_features_names(cge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lapa = cge[cge.station_name == \"Lapa\"] \\\n",
    "    .dropna(subset=[\"precipitation\", \"wind_velocity\", \"wind_direction\", \"temperature\", \"relative_humidity\", \"pressure\", \"wind_blow\"]) \\\n",
    "    .reset_index(drop=True) \\\n",
    "    .drop([\"thermal_sensation\"], axis=1)\n",
    "\n",
    "lapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lapa = get_wind_components(\n",
    "    lapa, \n",
    "    wind_velocity='wind_velocity', \n",
    "    wind_direction='wind_direction', \n",
    "    x_name='wind_velocity_x', \n",
    "    y_name='wind_velocity_y'\n",
    "    )\n",
    "\n",
    "lapa = lapa.drop(['wind_velocity'], axis=1)\n",
    "\n",
    "lapa = get_wind_components(\n",
    "    lapa, \n",
    "    wind_velocity='wind_blow', \n",
    "    wind_direction='wind_direction', \n",
    "    x_name='wind_blow_x', \n",
    "    y_name='wind_blow_y'\n",
    "    )\n",
    "\n",
    "lapa = lapa.drop(['wind_blow'], axis=1)\n",
    "lapa = lapa.drop(['wind_direction'], axis=1)\n",
    "lapa = resample_data(lapa)\n",
    "lapa = lapa.reset_index()\n",
    "lapa = lapa.set_index(\"timestamp\")\n",
    "\n",
    "lapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    'precipitation',\n",
    "    'temperature',\n",
    "    'relative_humidity',\n",
    "    'pressure',\n",
    "    'wind_velocity_x',\n",
    "    'wind_velocity_y',\n",
    "    'wind_blow_x',\n",
    "    'wind_blow_y'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.creation import CyclicalFeatures\n",
    "from feature_engine.datetime import DatetimeFeatures\n",
    "from feature_engine.imputation import DropMissingData\n",
    "from feature_engine.selection import DropFeatures\n",
    "from feature_engine.timeseries.forecasting import LagFeatures, WindowFeatures, ExpandingWindowFeatures\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf = DatetimeFeatures(\n",
    "    # the datetime variable\n",
    "    variables=\"index\",\n",
    "    \n",
    "    # the features we want to create\n",
    "    features_to_extract=[\n",
    "        \"month\",\n",
    "        \"week\",\n",
    "        \"day_of_month\",\n",
    "        \"hour\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "lagf = LagFeatures(\n",
    "    variables=cols, # the input variables\n",
    "    freq=[f\"{i}H\" for i in range(1,37)], # move 1 hr to 36 hrs forward\n",
    "    missing_values=\"ignore\"\n",
    ")\n",
    "\n",
    "winf = WindowFeatures(\n",
    "    variables=cols, # the input variables\n",
    "    window=[\"3H\", \"6H\", \"12H\", \"24H\"], # average of 3, 6, 12 and 24 previous hours\n",
    "    freq=\"1H\", # move 1 hr forward\n",
    "    functions=[\"mean\", \"std\", \"min\", \"max\"],\n",
    "    missing_values=\"ignore\"\n",
    ")\n",
    "\n",
    "cyclicf = CyclicalFeatures(\n",
    "    variables=[\"month\", \"hour\"], # The features we want to transform.\n",
    "    drop_original=False, # Whether to drop the original features.\n",
    ")\n",
    "\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"datetime_features\", dtf),\n",
    "        (\"lagf\", lagf),\n",
    "        (\"winf\", winf),\n",
    "        (\"Periodic\", cyclicf),\n",
    "    ]\n",
    ")\n",
    "\n",
    "lapa = pipe.fit_transform(lapa)\n",
    "lapa = lapa.drop([\"station\", \"station_name\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lapa.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
