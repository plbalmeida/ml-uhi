{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import io\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from unidecode import unidecode\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.multioutput import RegressorChain\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import HalvingGridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_steps(\n",
    "    df : pd.DataFrame, \n",
    "    y : str, \n",
    "    steps : int\n",
    "    ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get target feature steps ahead.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas data frame\n",
    "        Data frame with target feature.\n",
    "    \n",
    "    y : str\n",
    "        Target feature name.\n",
    "    \n",
    "    steps : int\n",
    "        Steps to forecast.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : pandas data frame\n",
    "        Data frame with target features.\n",
    "    \"\"\"\n",
    "\n",
    "    for i in range(steps):\n",
    "        df[f\"{y}_step_{i+1}\"] = df[y].shift(-i+1)\n",
    "    return df\n",
    "\n",
    "\n",
    "# models\n",
    "rid = RegressorChain(\n",
    "    base_estimator=RidgeCV(\n",
    "        alphas=[1e-3, 1e-2, 1e-1, 1],\n",
    "        cv=TimeSeriesSplit(n_splits=3, test_size=2000),\n",
    "    ),\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "gb = RegressorChain(\n",
    "    base_estimator=HalvingGridSearchCV(\n",
    "        estimator=HistGradientBoostingRegressor(random_state=123),\n",
    "        param_grid = {\n",
    "            \"max_depth\": np.arange(10, 40, 10, dtype=int),\n",
    "            \"learning_rate\": np.logspace(-3, -1, 3)\n",
    "        },\n",
    "        cv=TimeSeriesSplit(n_splits=3, test_size=2000),\n",
    "        aggressive_elimination=True,\n",
    "        scoring=\"neg_mean_squared_error\",\n",
    "        random_state=123,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "mlp = RegressorChain(\n",
    "    base_estimator=HalvingGridSearchCV(\n",
    "        estimator=MLPRegressor(max_iter=1000, random_state=123),\n",
    "        param_grid = {\n",
    "            \"hidden_layer_sizes\": [(100,), (100, 75, 25)],\n",
    "            \"activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"]\n",
    "        },\n",
    "        cv=TimeSeriesSplit(n_splits=3, test_size=2000),\n",
    "        aggressive_elimination=True,\n",
    "        scoring=\"neg_mean_squared_error\",\n",
    "        random_state=123,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "models = {\n",
    "    \"rid\": rid,\n",
    "    \"mlp\": mlp,\n",
    "    \"gb\": gb,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS credentials to read files on S3 bucket\n",
    "f = open('../credentials.json')\n",
    "credentials = json.load(f)\n",
    "\n",
    "s3_client = boto3.client(\n",
    "    \"s3\",\n",
    "    aws_access_key_id=credentials[\"Access key ID\"],\n",
    "    aws_secret_access_key=credentials[\"Secret access key\"]\n",
    "    )\n",
    "\n",
    "s3_resource = boto3.resource(\n",
    "    \"s3\",\n",
    "    aws_access_key_id=credentials[\"Access key ID\"],\n",
    "    aws_secret_access_key=credentials[\"Secret access key\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4954/3087448039.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f\"{y}_step_{i+1}\"] = df[y].shift(-i+1)\n",
      "/tmp/ipykernel_4954/3087448039.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f\"{y}_step_{i+1}\"] = df[y].shift(-i+1)\n",
      "/tmp/ipykernel_4954/3087448039.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f\"{y}_step_{i+1}\"] = df[y].shift(-i+1)\n",
      "/tmp/ipykernel_4954/3087448039.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f\"{y}_step_{i+1}\"] = df[y].shift(-i+1)\n",
      "/tmp/ipykernel_4954/3087448039.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f\"{y}_step_{i+1}\"] = df[y].shift(-i+1)\n",
      "/tmp/ipykernel_4954/3087448039.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f\"{y}_step_{i+1}\"] = df[y].shift(-i+1)\n"
     ]
    }
   ],
   "source": [
    "# getting preprocessed data\n",
    "prefix_objs = s3_resource.Bucket(\"cge\").objects.filter(Prefix=\"processed\")\n",
    "keys = [obj.key for obj in prefix_objs]\n",
    "for key in keys[1:]:\n",
    "    obj = s3_client.get_object(Bucket=\"cge\", Key=key)\n",
    "    df = pd.read_csv(io.BytesIO(obj[\"Body\"].read()))\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    station = df.station.unique()[0]\n",
    "    station_name = df.station_name.unique()[0]\n",
    "    ts = df[[\"timestamp\"]]\n",
    "    df = df.drop([\"station\", \"station_name\", \"timestamp\"], axis=1)\n",
    "    df = df.dropna(axis=1, how=\"all\")\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # target\n",
    "    y = make_steps(df=df[[\"temperature\"]], y=\"temperature\", steps=6).drop(\"temperature\", axis=1)\n",
    "    y = y.dropna()\n",
    "\n",
    "    # predictors\n",
    "    X = df.drop([\"temperature\"], axis=1)\n",
    "    X = X.loc[y.index.min():y.index.max()]\n",
    "\n",
    "    # scaling data\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X_standard = scaler.transform(X)\n",
    "\n",
    "    # train and test data split\n",
    "    test_size = 0.30\n",
    "    X_train_ref, X_test_ref, _, _ = train_test_split(X, y, test_size=0.30, shuffle=False)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_standard, y, test_size=test_size, shuffle=False)\n",
    "\n",
    "    # model training\n",
    "    for model in models:\n",
    "        models[model].fit(X_train, y_train)\n",
    "        y_pred = pd.DataFrame(models[model].predict(X_test), index=X_test_ref.index, columns=y.columns)\n",
    "        ts = ts.loc[y_pred.index.min():y_pred.index.max()]\n",
    "        y_pred[\"timestamp\"] = ts.timestamp \n",
    "        y_pred[\"station\"] = station\n",
    "        y_pred[\"station_name\"] = station_name\n",
    "\n",
    "        # writing predictions to S3 bucket\n",
    "        station_ = unidecode(key.lower().replace(\" \", \"_\").replace(\"processed/\", \"\").replace(\".csv\", \"\"))\n",
    "        station_ = station_ + \"_\" + model\n",
    "        buffer = io.StringIO()\n",
    "        y_pred.to_csv(buffer)\n",
    "        s3_resource.Object(\"cge\", f\"output/{station_}.csv\").put(Body=buffer.getvalue())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
