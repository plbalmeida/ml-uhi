{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import datetime\n",
    "import io\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.units as munits\n",
    "import numpy as np\n",
    "from unidecode import unidecode\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.multioutput import RegressorChain\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import HalvingGridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_steps(\n",
    "    df : pd.DataFrame, \n",
    "    y : str, \n",
    "    steps : int\n",
    "    ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get target feature steps ahead.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas data frame\n",
    "        Data frame with target feature.\n",
    "    \n",
    "    y : str\n",
    "        Target feature name.\n",
    "    \n",
    "    steps : int\n",
    "        Steps to forecast.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : pandas data frame\n",
    "        Data frame with target features.\n",
    "    \"\"\"\n",
    "\n",
    "    for i in range(steps):\n",
    "        df[f\"{y}_step_{i+1}\"] = df[y].shift(-i+1)\n",
    "    return df\n",
    "\n",
    "\n",
    "# models\n",
    "rid = RegressorChain(\n",
    "    base_estimator=RidgeCV(\n",
    "        alphas=[1e-3, 1e-2, 1e-1, 1],\n",
    "        cv=TimeSeriesSplit(n_splits=3, test_size=2000),\n",
    "    ),\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "gb = RegressorChain(\n",
    "    base_estimator=HalvingGridSearchCV(\n",
    "        estimator=HistGradientBoostingRegressor(random_state=123),\n",
    "        param_grid = {\n",
    "            \"max_depth\": np.arange(10, 40, 10, dtype=int),\n",
    "            \"learning_rate\": np.logspace(-3, -1, 3)\n",
    "        },\n",
    "        cv=TimeSeriesSplit(n_splits=3, test_size=2000),\n",
    "        aggressive_elimination=True,\n",
    "        scoring=\"neg_mean_squared_error\",\n",
    "        random_state=123,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "mlp = RegressorChain(\n",
    "    base_estimator=HalvingGridSearchCV(\n",
    "        estimator=MLPRegressor(max_iter=1000, random_state=123),\n",
    "        param_grid = {\n",
    "            \"hidden_layer_sizes\": [(100,), (100, 75, 25)],\n",
    "            \"activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"]\n",
    "        },\n",
    "        cv=TimeSeriesSplit(n_splits=3, test_size=2000),\n",
    "        aggressive_elimination=True,\n",
    "        scoring=\"neg_mean_squared_error\",\n",
    "        random_state=123,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "models = {\n",
    "    \"rid\": rid,\n",
    "    \"mlp\": mlp,\n",
    "    \"gb\": gb,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS credentials to read files on S3 bucket\n",
    "f = open('../credentials.json')\n",
    "credentials = json.load(f)\n",
    "\n",
    "s3_client = boto3.client(\n",
    "    \"s3\",\n",
    "    aws_access_key_id=credentials[\"Access key ID\"],\n",
    "    aws_secret_access_key=credentials[\"Secret access key\"]\n",
    "    )\n",
    "\n",
    "s3_resource = boto3.resource(\n",
    "    \"s3\",\n",
    "    aws_access_key_id=credentials[\"Access key ID\"],\n",
    "    aws_secret_access_key=credentials[\"Secret access key\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting preprocessed data\n",
    "prefix_objs = s3_resource.Bucket(\"cge\").objects.filter(Prefix=\"processed\")\n",
    "keys = [obj.key for obj in prefix_objs]\n",
    "# for key in keys:\n",
    "#     obj = s3_client.get_object(Bucket=\"cge\", Key=key)\n",
    "#     df = pd.read_csv(io.BytesIO(obj[\"Body\"].read()))\n",
    "#     df = df.reset_index(drop=True)\n",
    "#     station = df.station.unique()[0]\n",
    "#     station_name = df.station_name.unique()[0]\n",
    "#     ts = df[[\"timestamp\"]]\n",
    "#     df = df.drop([\"station\", \"station_name\", \"timestamp\"], axis=1)\n",
    "\n",
    "#     df = df.dropna(axis=1, how=\"all\")\n",
    "#     df = df.dropna()\n",
    "    \n",
    "#     y = make_steps(df=df[[\"temperature\"]], y=\"temperature\", steps=6).drop(\"temperature\", axis=1)\n",
    "#     y = y.dropna()\n",
    "\n",
    "#     X = df.drop([\"temperature\"], axis=1)\n",
    "#     X = X.loc[y.index.min():y.index.max()]\n",
    "\n",
    "#     scaler = StandardScaler()\n",
    "#     scaler.fit(X)\n",
    "#     X_standard = scaler.transform(X)\n",
    "\n",
    "#     test_size = 0.30\n",
    "#     X_train_ref, X_test_ref, _, _ = train_test_split(X, y, test_size=0.30, shuffle=False)\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X_standard, y, test_size=test_size, shuffle=False)\n",
    "\n",
    "#     models[\"rid\"].fit(X_train, y_train)\n",
    "#     y_pred = pd.DataFrame(models[\"rid\"].predict(X_test), index=X_test_ref.index, columns=y.columns)\n",
    "#     ts = ts.loc[y_pred.index.min():y_pred.index.max()]\n",
    "#     y_pred[\"timestamp\"] = ts.timestamp \n",
    "#     y_pred[\"station\"] = station\n",
    "#     y_pred[\"station_name\"] = station_name\n",
    "\n",
    "#     # writing predictions to S3 bucket\n",
    "#     station_ = unidecode(key.lower().replace(\" \", \"_\").replace(\"processed/\", \"\"))\n",
    "#     buffer = io.StringIO()\n",
    "#     y_pred.to_csv(buffer)\n",
    "#     s3_resource.Object(\"cge\", f\"output/{station_}\").put(Body=buffer.getvalue())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = cge[X_test_ref.index[0]:X_test_ref.index[-1]][[\"timestamp\", \"temperature\"]].set_index(\"timestamp\")\n",
    "test.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.index = pd.to_datetime(test.index)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.timestamp = pd.to_datetime(ts.timestamp)\n",
    "y_pred[\"timestamp\"] = ts[y_pred.index[0]:y_pred.index[-1]][\"timestamp\"]\n",
    "y_pred = y_pred.dropna()\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = mdates.ConciseDateConverter()\n",
    "munits.registry[np.datetime64] = converter\n",
    "munits.registry[datetime.date] = converter\n",
    "munits.registry[datetime.datetime] = converter\n",
    "\n",
    "for i in y_pred.index[-200:-20]:\n",
    "    pred = y_pred.loc[[i]]\n",
    "    start_date = pred.timestamp.unique()[0] + np.timedelta64(1,'h')\n",
    "    pred = pred.drop(\"timestamp\", axis=1).T\n",
    "    pred.index = pd.date_range(start=start_date, periods=6, freq=\"H\")\n",
    "    pred.columns = [\"temperature\"]\n",
    "\n",
    "    past_data = 12*3\n",
    "    train_plot = test[pred.index[0]-np.timedelta64(past_data,'h'):pred.index[0]-np.timedelta64(1,'h')]\n",
    "    test_plot = test[pred.index[0]:pred.index[-1]]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9,3))\n",
    "    ax.plot(train_plot, label=f\"Observed (last {past_data} hours)\", marker=\".\", markersize=10, alpha=0.8)\n",
    "    ax.plot(test_plot, label=\"Test\", ls=\"\", marker=\".\", markersize=10, color=\"forestgreen\", alpha=0.8)\n",
    "    ax.plot(pred, label=\"Predicted\", ls=\"\", marker=\"X\", markersize=6, color=\"orangered\", alpha=0.8)\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "mse = []\n",
    "for i in y_pred.index:\n",
    "    pred = y_pred.loc[[i]]\n",
    "    start_date = pred.timestamp.unique()[0] + np.timedelta64(1,'h')\n",
    "    pred = pred.drop(\"timestamp\", axis=1).T\n",
    "    pred.index = pd.date_range(start=start_date, periods=6, freq=\"H\")\n",
    "    pred.columns = [\"temperature\"]\n",
    "    test_plot = test[pred.index[0]:pred.index[-1]]\n",
    "    try:\n",
    "        mse.append(mean_squared_error(test_plot, pred, squared=False))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MSE\")\n",
    "print(f\"Mean: {np.round(np.mean(mse), 2)}\") \n",
    "print(f\"Standard deviation: +-{np.round(np.std(mse), 2)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
